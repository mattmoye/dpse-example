#-*- mode: org -*-
#+STARTUP:    align fold hidestars oddeven
#+TITLE: BioHH1 example analysis
#+AUTHOR: Dan Meliza

This directory is a complete example of an analysis to estimate the parameters
and state variables of a conductance-based neuron model using intracellular
current clamp data. The analysis has several steps.

* Install prerequisites

You will need to have g++, IPOPT, Python, and sympy for this tutorial. This
example has been tested with g++ 4.3, IPOPT 3.10.2, Python 2.7, and sympy
0.7.1.

On kkong, these programs have already been installed through softenv. Type

: soft add +python +ipopt

to add them to your environment.  You will need to do this each time you login,
or else set up a =.soft= file to load them automatically.

* Specify the model

The model comprises a set of ordinary differential equations, which are
specified in a file called =equations.txt=. This directory contains an example
model with 12 state variables and 73 parameters. The file is commented.

* Generate the estimation code

Next, a python program (originally by Bryan Toth) converts the symbolic
description of the model in =equation.txt= into C++ functions. Essentially this
involves computing a lot of derivatives to get the Jacobian and Hessian. To run
this step:

: python model/makecode.py

Expect this to take a long time, but you only need to run this when the
=equations.txt= file changes. The makecode script expects to find
=equations.txt= in the current directory.

* Compile the estimation code

Successful completion of the previous step will result in generation of a number
of C++ files and a Makefile. The Makefile expects to find IPOPT using
pkg-config. If you have problems you may need to edit the COIN_LDFLAGS and
COIN_CFLAGS lines in the Makefile. You will also need a reasonably modern C++
compiler (e.g. gcc 4.3 or later). Older compilers may run out of memory. To
compile on the Margoliash lab cluster,

: CXX=g++44 make

This step also takes a long time.

* Run the estimation procedure

If the previous step completes successfully, you will have an executable called
=biohh1=. At this point you can adjust the parameter guesses and bounds by
editing =specs.txt=. This file is also commented. Changes to this file do not
require a recompilation of the executable. Make sure it specifies the location
of the input data files correctly, or you'll get a segmentation fault. You may
also want to edit =biohh1.opt= to set tolerances and maximum number of
iterations. Consult the IPOPT documentation for more information on the
parameters. To run the estimation:

: ./biohh1

Guess what? This takes a long time, too.  You will see some nice status updates
as the estimates converge.  At the end there will be two files you can inspect.
=param.dat= has the parameter estimates; =data.dat= has the state variables.

* Run forward predictions

The completed model can be used to predict forward in time by integrating with
the estimated state and parameter values. The example =specs.txt= file uses
1500 ms for the assimilation, leaving quite a bit of data for prediction. Chris
Knowlton's =ipopt_predict= script uses the equations.txt file and the
output from IPOPT to generate forward predictions.  To run the prediction for
the rest of the data in the example:

: python model/ipopt_predict.py -e equations.txt pred.dat 258334

The last commandline parameter specifies the number of time points to integrate
forward after the end of the assimilation period.

* Next steps

Examine the format of the current and voltage input data files. Each is a single
column of values. The units are mV for voltage and nA for current. You can
generate your own files to analyze from your data. If you're using the cell
database on kkong (/home3/hvc_cell_database), you can export data from an epoch
to a table, which has three columns corresponding to time, voltage, and current
(in picoamps). Use =awk= to export the data into the IPOPT format:

: awk '/+|-/ {print $2}' FILENAME.tbl > FILENAME_v.dat
: awk '/+|-/ {print $3/1000}' FILENAME.tbl > FILENAME_i.dat

You should create a separate directory for each analysis and copy over the
specs.txt, equations.txt, biohh1.opt, and biohh1 executable. You'll need to edit the
specs.txt file to refer to the data files for each analysis, set how many
samples to use, etc.

After you've done this for a few epochs, you're ready to move on to batch
processing (tutorial not written yet).
